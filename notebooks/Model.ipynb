{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SeparableConv2D, Add\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"../assets/models/\"\n",
    "DATA_DIR = \"../assets/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_113_80.h5f\"\n",
    "large = False\n",
    "# model_name = \"cnn_227_160.h5f\"\n",
    "# large = True\n",
    "\n",
    "import re\n",
    "p = re.compile(r\"cnn_(\\d+)_(\\d+).h5f\")\n",
    "h, w = p.findall(model_name)[0]\n",
    "h, w = int(h), int(w)\n",
    "\n",
    "TARGET_SIZE = (h, w)\n",
    "\n",
    "# ZOOM_FACTOR = 2\n",
    "# TARGET_SIZE = (SRC_HEIGHT//ZOOM_FACTOR, SRC_WIDTH//ZOOM_FACTOR)\n",
    "\n",
    "print(f\"target_size = {TARGET_SIZE}\")\n",
    "\n",
    "OUTPUT_SHAPE = 3\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORD_DIR = \"../assets/data/records/\"\n",
    "EM_RECORD_DIR = \"../assets/data/emulator_records/\"\n",
    "\n",
    "p = re.compile(r\".*images-\\d+-(\\d+)\\.tfrec\")\n",
    "\n",
    "X = glob.glob(os.path.join(RECORD_DIR, 'images-*.tfrec'))[:50]+\\\n",
    "    glob.glob(os.path.join(EM_RECORD_DIR, 'images-*.tfrec'))\n",
    "X = filter(lambda x: len(p.findall(x)) > 0, X)\n",
    "X = list(X)\n",
    "\n",
    "N = sum(map(lambda x: int(p.findall(x)[0]), X))\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.image.resize(image, TARGET_SIZE)\n",
    "    image = tf.reverse(image, axis=[-1])\n",
    "    #image = tf.reshape(image, [*TARGET_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"x_center\": tf.io.FixedLenFeature([], tf.float32),  \n",
    "        \"y_center\": tf.io.FixedLenFeature([], tf.float32),  \n",
    "        \"confidence\": tf.io.FixedLenFeature([], tf.float32),  \n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = (example['x_center'], example['y_center'], example['confidence'])\n",
    "    label = [tf.cast(x, tf.float32) for x in label]\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def read_dataset(filenames):\n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n",
    "\n",
    "    opt = tf.data.Options()\n",
    "    opt.experimental_deterministic = False\n",
    "    dataset = dataset.with_options(opt) \n",
    "\n",
    "    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, label):\n",
    "    #image = tf.image.random_flip_left_right(image)\n",
    "    #image = tf.image.random_saturation(image, 0, 2)\n",
    "    return image, label \n",
    "\n",
    "def get_train_dataset(filenames):\n",
    "    d = read_dataset(filenames)\n",
    "#     d = d.map(data_augment, num_parallel_calls=AUTO)\n",
    "    d = d.repeat()\n",
    "    d = d.shuffle(2048)\n",
    "    d = d.batch(BATCH_SIZE)\n",
    "    d = d.prefetch(AUTO)\n",
    "    return d\n",
    "\n",
    "def get_test_dataset(filenames):\n",
    "    d = read_dataset(filenames)\n",
    "    d = d.batch(BATCH_SIZE)\n",
    "    d = d.cache()\n",
    "    d = d.prefetch(AUTO)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = read_dataset(X)\n",
    "full_dataset = full_dataset.shuffle(10, reshuffle_each_iteration=False)\n",
    "\n",
    "split_factor = 8\n",
    "\n",
    "def is_test(x, y):\n",
    "    return x % split_factor == 0\n",
    "\n",
    "def is_train(x, y):\n",
    "    return not is_test(x, y)\n",
    "\n",
    "def recover(x, y):\n",
    "    return y\n",
    "\n",
    "test_dataset = full_dataset.enumerate() \\\n",
    "                    .filter(is_test) \\\n",
    "                    .map(recover)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.cache()\n",
    "test_dataset = test_dataset.prefetch(AUTO)\n",
    "\n",
    "train_dataset = full_dataset.enumerate() \\\n",
    "                    .filter(is_train) \\\n",
    "                    .map(recover)\n",
    "train_dataset = train_dataset.shuffle(2048)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(AUTO)\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    break\n",
    "for i, (image, label) in enumerate(zip(images, labels)):\n",
    "    if i == 2:\n",
    "        print(label)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_accuracy(y_true, y_pred, thresh=0.8):\n",
    "    true_cls = y_true[:,2]\n",
    "    pred_cls = y_pred[:,2]\n",
    "    pred_cls = tf.math.greater(pred_cls, thresh)\n",
    "    pred_cls = tf.cast(pred_cls, true_cls.dtype)\n",
    "    \n",
    "    abs_err = tf.math.abs(true_cls-pred_cls)\n",
    "    return 1-tf.math.reduce_mean(abs_err)\n",
    "\n",
    "def position_accuracy(y_true, y_pred):\n",
    "    true_cls = y_true[:,2]\n",
    "    true_pos = y_true[:,:2]\n",
    "    pred_pos = y_pred[:,:2]\n",
    "    \n",
    "    abs_err = tf.math.abs(true_pos-pred_pos)\n",
    "    dist_sqr_err = tf.math.reduce_sum(tf.math.square(abs_err), axis=1)\n",
    "    dist_err = tf.math.sqrt(dist_sqr_err)\n",
    "    \n",
    "    # only consider when object is there\n",
    "    dist_err = tf.math.multiply(dist_err, true_cls)\n",
    "    net_err = tf.math.reduce_sum(dist_err)\n",
    "    total_objects = tf.math.reduce_sum(true_cls)\n",
    "    \n",
    "    mean_err = net_err / total_objects\n",
    "    return 1-mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(large=False):\n",
    "    alpha = 0.2\n",
    "    dropout = 0.1\n",
    "\n",
    "    inputs = Input(shape=TARGET_SIZE+(3,))\n",
    "\n",
    "#    x_skip = inputs\n",
    "    \n",
    "    x = Conv2D(16, (3, 3))(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    if large:\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "    else:\n",
    "        x = MaxPooling2D((3, 3))(x)\n",
    "    \n",
    "#     x_skip = Conv2D(64, (16, 16))(x_skip)\n",
    "#     x_skip = MaxPooling2D((17,17))(x_skip)\n",
    "#     x = Add()([x, x_skip])\n",
    "\n",
    "    # larger network\n",
    "    if large:\n",
    "        x = Conv2D(64, (3, 3))(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = SeparableConv2D(128, (3, 3), padding=\"same\")(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    if large:\n",
    "        x = Dense(128)(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "    x = Dense(64)(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Dense(32)(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Dense(OUTPUT_SHAPE)(x)\n",
    "    outputs = x\n",
    "    #outputs = LeakyReLU(alpha)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "model = create_model(large=large)\n",
    "\n",
    "model.load_weights(os.path.join(MODEL_DIR, model_name))\n",
    "#model.load_weights(os.path.join(MODEL_DIR, \"cnn_227_160.h5f\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=\"mae\",\n",
    "    metrics=[detect_accuracy, position_accuracy],\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int((split_factor-1)/split_factor*N)\n",
    "n_test = int(1/split_factor*N)\n",
    "\n",
    "steps_per_epoch = n_train // BATCH_SIZE\n",
    "validation_steps = n_test // BATCH_SIZE\n",
    "\n",
    "print(\"steps per epoch: {0}\".format(steps_per_epoch))\n",
    "print(\"validation steps {0}\".format(validation_steps))\n",
    "\n",
    "TOTAL_EPOCHS = 5\n",
    "\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=TOTAL_EPOCHS,\n",
    "    validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(MODEL_DIR, model_name))\n",
    "# model.save_weights(\"../models/cnn_227_160.h5f\")\n",
    "# model.save_weights(\"../models/cnn_113_80.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(images)\n",
    "y_true = labels\n",
    "print(detect_accuracy(y_pred, y_true))\n",
    "print(position_accuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
